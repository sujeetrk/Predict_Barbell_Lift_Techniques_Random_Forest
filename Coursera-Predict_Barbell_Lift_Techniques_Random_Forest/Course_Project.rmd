---
title: "Predicting Barbell Lift Techniques Using Random Forest"
author: "Sujeeth R K"
date: "October 29, 2025"
output:
  html_document:
    toc: yes
---
The random forest algorithm from the randomForest R package was selected to build this 
classifier. This choice was particularly suitable given the time constraints and the inherent 
non-linearity present in the dataset. Random forest offers significant benefits, including 
minimal parameter tuning requirements while delivering strong performance and 
straightforward implementation.

Tree-based algorithms excel at handling non-linear classification tasks. The initial strategy 
involved applying bagging techniques (such as decision trees and random forest), followed by 
testing boosting methods (like AdaBoost and Stochastic Gradient Boosting). Due to time 
limitations, only the random forest approach was evaluated, which yielded excellent outcomes 
with perfect classification accuracy (100%) on the validation dataset.

Key stages in the model development process:

1. Remove timestamp-related columns from both training and validation datasets.

2. Drop columns containing a high proportion of missing values from both datasets.

3. Exclude columns exhibiting nearly zero variance from both datasets.

4. Split the training dataset into training and testing subsets (for cross-validation purposes).

5. Build a random forest classifier on the training subset using variable importance metrics.

6. Evaluate model performance on the testing subset.

7. Generate and save predictions for the validation dataset.

Now let's walk through the implementation.

Loading required libraries
```{r, message = FALSE, warning = FALSE}
library(caret)
library(ggplot2)
library(randomForest)
```
The training dataset contained numerous columns with missing or NA values. Proper identification 
of NA values was critical for data preprocessing. The following code loads both training and 
validation datasets from their respective CSV files.
```{r, }
data = read.table("pml-training.csv", sep=",", header = TRUE, na.strings=c("","NA","#DIV/0!"))
validation_data = read.table("pml-testing.csv", sep=",", header = TRUE, na.strings=c("","NA"
,"#DIV/0!"))
```
After loading the data, timestamp-associated columns were excluded. These features don't contribute 
meaningful information for predicting the output class and pose challenges during processing.
```{r}
#removing timestamp columns
data <- data[,c(-1,-3,-4,-5)]
validation_data <- validation_data[,c(-1,-3,-4,-5)]
```
Several columns in the training dataset contained more than 95% NA values, while the 
remaining columns had complete data. Additionally, these sparse columns were redundant (being 
derivatives of other features) and offered limited predictive value. Therefore, they were also 
removed from the dataset.
```{r}
#removing cols with only NA values
# Custom function to remove columns with NAs
removeColsWithNAs <- function(df) {
  na_cols <- sapply(df, function(x) sum(is.na(x)) / length(x) > 0.95)
  list(a = df[, !na_cols], b = !na_cols)
}
ret <- removeColsWithNAs(data)
data <- ret$a
validation_data <- validation_data[,ret$b]
```
This preprocessing step successfully reduced the predictor count from 156 to 56.
The subsequent step involves removing features with minimal variance.
```{r}
#removing predictors with zero variance
nzv <- nearZeroVar(data)
data <- data[,-nzv]
validation_data <- validation_data[,-nzv]
```

Dividing the training dataset into training and testing subsets.
```{r}
set.seed(1729)
#partition train data into training and testing data
inTrain = createDataPartition(y = data$classe, p = 0.7, list = FALSE)
training = data[inTrain, ]
testing = data[-inTrain, ]
```

Visualization of yaw_belt versus num_window in the training subset:
```{r, echo = FALSE}
qplot(training$yaw_belt, training$num_window, color = training$classe, geom = "jitter")
```

This visualization demonstrates the non-linear nature of the classification challenge.

Visualization of mTry versus Out-Of-Bag-Error (using 501 trees):
```{r}
#Training a randomForest model
#finding optimal value for mTry parameter
tuneRF(training[,-55], training[,55], nTryTree = 501, plot = TRUE)
```
Principal Component Analysis (PCA) for dimensionality reduction was not implemented due to the 
prohibitive computational time required for such a large dataset.

Training the model on the training subset and generating predictions for the testing subset
```{r}
set.seed(223)
model <- randomForest(classe ~ ., data = training, importance = TRUE, ntree = 501)
pred <- predict(model, newdata = testing)
```

Visualization showing variables ranked by their overall importance:
```{r, echo = FALSE, fig.width = 10, fig.height = 10}
vi <- varImp(model)
vi$sum <- rowSums(vi)
vi <- vi[with(vi, order(-sum)),]
par(mai=c(1,5,1,1))
plot(vi$sum,1:54, yaxt='n', main = "Variable Importance", xlab = "Importance", ylab = "", pch = 16, col = "red")
axis(2,at = 1:54, labels = rownames(vi), las = 2)
abline(h = 1:54, v = 0, col = "gray60")
```

Confusion matrix showing prediction results on the testing subset
```{r, echo = FALSE}
table(pred, testing$classe)
```

Overall and per-class accuracy metrics
```{r, echo = FALSE}
# Custom accuracy function
accuracy <- function(actual, predicted) {
  sum(actual == predicted) / length(actual)
}
acc <- accuracy(testing$classe, pred)
cat("Overall Accuracy = ",acc)
classes <- unique(testing$classe)
tb <- table(pred, testing$classe)
row_sum <- rowSums(tb)
for(i in 1:length(classes)) {
  cat("Accuracy for class ", levels(classes)[i]," = ", tb[i,i]/row_sum[i],"\n")
}
```

Detailed information about the trained model
```{r, echo = FALSE}
model
```

Note: The estimated out-of-sample error rate is 0.22%

Visualization of tree count versus MSE (Mean Squared Error)
```{r}
plot(model, log = "x")
legend("topright", colnames(model$err.rate), col=1:6, fill=1:6)
```

Final predictions generated for the validation dataset
```{r}
pred <- predict(model, newdata = validation_data)
pred
```
